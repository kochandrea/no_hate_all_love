{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was run on an Amazon SageMaker ml.c5.4xlarge instance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import LancasterStemmer \n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_functions as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in test.csv and train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pf.read_pickle(bucket_name='advancedml-koch-mathur-hinkson', filename='sub_train_df14_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['split', 'cleaned_w_stopwords', 'cleaned_no_stem', 'cleaned_porter', 'cleaned_lancaster', 'bigrams_unstemmed',\n",
    "       'perc_upper', 'num_exclam', 'num_words', 'perc_stopwords',\n",
    "       'num_upper_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 49)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count',\n",
       "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
       "       'cleaned_lancaster_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column called \"toxicity_category\" in the train data frame categorizing comments as toxic (\"1\") or non-toxic (\"0\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['toxicity_category'] = train.target.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train.csv into training (80%) and hold out sets (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation: https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "msk = np.random.rand(len(train)) < 0.8\n",
    "train_set = train[msk]\n",
    "hold_out_set = train[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74767\n",
      "1     5391\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18577\n",
      "1     1265\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(hold_out_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74767\n",
      "1     5391\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = train_set[train_set.toxicity_category == 1]\n",
    "nontoxic = train_set[train_set.toxicity_category == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80158, 50), (5391, 50), (74767, 50))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, toxic.shape, nontoxic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataset to be include an equal number of toxic and nontoxic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = len(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = train_set.sample(quarter*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set of 25% toxic and 75% nontoxic comments, and shuffle the data such that you do not have a data set of grouped toxic and grouped nontoxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    16173\n",
      "1     5391\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_25 = toxic.append(nontoxic.sample(len(toxic)*3))\n",
    "prepared_25 = prepared_25.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_25.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - weighted 25% toxic, 75% nontoxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model now\n"
     ]
    }
   ],
   "source": [
    "classifier, output, fitted_vectorizer = mf.run_model(model_df=prepared_25, \n",
    "                                                     model_type=\"SVM\", \n",
    "                                                     comments = \"cleaned_no_stem_str\", \n",
    "                                                     train_perc=0.95, \n",
    "                                                     target=\"toxicity_category\", \n",
    "                                                     see_inside=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8608534322820037\n",
      "Overall Precision: 0.8604651162790697\n",
      "Overall Recall: 0.5401459854014599\n",
      "Overall F1 Score: 0.6636771300448431\n",
      "ROC_AUC: 0.755\n",
      "\n",
      "Target Accuracy: 0.5401459854014599\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.5401459854014599\n",
      "Target F1 Score: 0.7014218009478673\n",
      "\n",
      "Non-Target Accuracy: 0.9701492537313433\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9701492537313433\n",
      "Non-Target F1 Score: 0.9848484848484849\n",
      "\n",
      "Strong Identity Accuracy: 0.5\n",
      "Strong Identity Precision: 1.0\n",
      "Strong Identity Recall: 0.5\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.5\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.5\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.6021505376344086\n",
      "Insults Precision: 1.0\n",
      "Insults Recall: 0.6\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.2\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.2\n",
      "Threats F1 Score: 0.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall': {'Accuracy': 0.8608534322820037,\n",
       "  'Precision': 0.8604651162790697,\n",
       "  'Recall': 0.5401459854014599,\n",
       "  'F1': 0.6636771300448431,\n",
       "  'ROC_AUC': 0.755},\n",
       " 'Target': {'Accuracy': 0.5401459854014599,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.5401459854014599,\n",
       "  'F1': 0.7014218009478673},\n",
       " 'Non-Target': {'Accuracy': 0.2, 'Precision': 1.0, 'Recall': 0.2, 'F1': 0.0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.get_metrics(output=output, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count',\n",
      "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
      "       'cleaned_lancaster_str', 'toxicity_category', 'predicted', 'y_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hold_out_results = mf.run_model_test(model_df=hold_out_set, \n",
    "                                     clf=classifier, \n",
    "                                     vectorizer=fitted_vectorizer, \n",
    "                                     comments=\"cleaned_no_stem_str\", target=\"toxicity_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_results.to_csv(\"holdout_results\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9417397439774217\n",
      "Overall Precision: 0.5376121463077985\n",
      "Overall Recall: 0.6158102766798419\n",
      "Overall F1 Score: 0.574060427413412\n",
      "ROC_AUC: 0.79\n",
      "\n",
      "Target Accuracy: 0.6158102766798419\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.6158102766798419\n",
      "Target F1 Score: 0.7622309197651663\n",
      "\n",
      "Non-Target Accuracy: 0.9639338967540507\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9639338967540507\n",
      "Non-Target F1 Score: 0.9816357855498301\n",
      "\n",
      "Strong Identity Accuracy: 0.5619834710743802\n",
      "Strong Identity Precision: 0.9384615384615385\n",
      "Strong Identity Recall: 0.5545454545454546\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.7058823529411765\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.7014925373134329\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.7034339229968782\n",
      "Insults Precision: 0.9819819819819819\n",
      "Insults Recall: 0.7055016181229773\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.1875\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.16129032258064516\n",
      "Threats F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_out_metrics = mf.get_metrics(output=hold_out_results, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "WRITEBACKIFCOPY base is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1081fc725b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mplot_coefficients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-1081fc725b03>\u001b[0m in \u001b[0;36mplot_coefficients\u001b[0;34m(classifier, feature_names, top_features)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# create plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"red\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"blue\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_coefficients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtop_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_coefficients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-1081fc725b03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# create plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"red\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"blue\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_coefficients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtop_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_coefficients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         return self._inequality(other, operator.lt, '_lt_',\n\u001b[0;32m--> 304\u001b[0;31m                                 \u001b[0;34m\"Comparing a sparse matrix with a scalar \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                                 \u001b[0;34m\"greater than zero using < is inefficient, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                                 \"try using >= instead.\")\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_inequality\u001b[0;34m(self, other, op, op_name, bad_scalar_msg)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Dense other.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_scalar_binopt\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mare\u001b[0m \u001b[0madded\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mProduces\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mspmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcanonical\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliminate_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1059\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: WRITEBACKIFCOPY base is read-only"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Citation:  https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = np.ravel(classifier.coef_)\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=\"right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_coefficients(classifier, fitted_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - weighted 1/3 toxic, 2/3 nontoxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10664\n",
      "1     5332\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_33 = toxic.append(nontoxic.sample(len(toxic)*2))\n",
    "prepared_33 = prepared_33.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_33.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model now\n"
     ]
    }
   ],
   "source": [
    "classifier, output, fitted_vectorizer = mf.run_model(model_df=prepared_33, \n",
    "                                                     model_type=\"SVM\", \n",
    "                                                     comments = \"cleaned_no_stem_str\", \n",
    "                                                     train_perc=0.95, \n",
    "                                                     target=\"toxicity_category\", \n",
    "                                                     see_inside=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count',\n",
      "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
      "       'cleaned_lancaster_str', 'toxicity_category', 'predicted', 'y_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hold_out_results = mf.run_model_test(model_df=hold_out_set, \n",
    "                                     clf=classifier, \n",
    "                                     vectorizer=fitted_vectorizer, \n",
    "                                     comments=\"cleaned_no_stem_str\", target=\"toxicity_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9248949845639961\n",
      "Overall Precision: 0.45987963891675027\n",
      "Overall Recall: 0.6925981873111783\n",
      "Overall F1 Score: 0.5527426160337553\n",
      "ROC_AUC: 0.817\n",
      "\n",
      "Target Accuracy: 0.6925981873111783\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.6925981873111783\n",
      "Target F1 Score: 0.8183846497099508\n",
      "\n",
      "Non-Target Accuracy: 0.9415785191212368\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9415785191212368\n",
      "Non-Target F1 Score: 0.9699103176598776\n",
      "\n",
      "Strong Identity Accuracy: 0.6535433070866141\n",
      "Strong Identity Precision: 0.9425287356321839\n",
      "Strong Identity Recall: 0.6776859504132231\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.7611940298507462\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.7611940298507462\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.742914979757085\n",
      "Insults Precision: 0.9849108367626886\n",
      "Insults Recall: 0.7471383975026015\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.3793103448275862\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.35714285714285715\n",
      "Threats F1 Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_out_metrics = mf.get_metrics(output=hold_out_results, detailed=True, should_print=True, round_to=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
