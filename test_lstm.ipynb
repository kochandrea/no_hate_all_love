{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import ssl\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud\n",
    "from collections import Counter, OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn = pd.read_pickle('jigsaw_toxic/20pct_model_35toxic_train.pkl')\n",
    "# val = pd.read_pickle('jigsaw_toxic/20pct_model_35toxic_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA? True cuda:0\n"
     ]
    }
   ],
   "source": [
    "import jigsaw_toxic.exec_lstm as exl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = trn.drop('label', axis=1)\n",
    "# y_train = trn['label']\n",
    "# test_sample = val.sample( n=math.ceil(len(X_train)*0.2), random_state=1008 )\n",
    "# X_test = test_sample.drop('label', axis=1)\n",
    "# y_test = test_sample['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model = exl.LSTMModel(X_train[:500], y_train[:500], X_test[:100], y_test[:100], \n",
    "#                            hidden_dim=50, num_layers=1, embed_dim=50, batch_size=1,\n",
    "#                            dropout=0, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exl.USE_CUDA:\n",
    "#     print(exl.USE_CUDA)\n",
    "#     lstm_model = lstm_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (loss_fcn): NLLLoss()\n",
       "  (embedding): Embedding(7500, 50)\n",
       "  (lstm): LSTM(50, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EPOCHS = 6\n",
    "# hist_lstm = np.zeros(NUM_EPOCHS)\n",
    "# model_name=\"toy_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6; Train Size: 500; Test Size: 100)\n",
      "Starting epoch 0...\n",
      "Epoch 0, Negative Log Linear Loss: 0.38605058193206787\n",
      "\n",
      "Starting Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 F1 Score: 0.0\n",
      "Starting epoch 1...\n",
      "\n",
      "Starting Evaluation\n",
      "Epoch 1 F1 Score: 0.0\n",
      "Starting epoch 2...\n",
      "Epoch 2, Negative Log Linear Loss: 0.3697086274623871\n",
      "\n",
      "Starting Evaluation\n",
      "Epoch 2 F1 Score: 0.0\n",
      "Starting epoch 3...\n",
      "\n",
      "Starting Evaluation\n",
      "Epoch 3 F1 Score: 0.0\n",
      "Starting epoch 4...\n",
      "Epoch 4, Negative Log Linear Loss: 0.36790764331817627\n",
      "\n",
      "Starting Evaluation\n",
      "Epoch 4 F1 Score: 0.0\n",
      "Starting epoch 5...\n",
      "\n",
      "Starting Evaluation\n",
      "Epoch 5 F1 Score: 0.0\n",
      "Highest F1 Score: 0.0, Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "# results, model_state_dict = lstm_model.run_model(y_train[:500], X_test[:100], y_test[:100], NUM_EPOCHS, \n",
    "#                                                  hist_lstm, text_col='cleaned_no_stem', savestate=model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Size: 100\n",
      "Overall Accuracy: 0.89\n",
      "Overall Precision: 0.0\n",
      "Overall Recall: 0.0\n",
      "Overall F1 Score: 0.0\n",
      "ROC_AUC: 0.5\n",
      "\n",
      "Group Size: 11\n",
      "Target Accuracy: 0.0\n",
      "Target Precision: 0.0\n",
      "Target Recall: 0.0\n",
      "Target F1 Score: 0.0\n",
      "\n",
      "Group Size: 89\n",
      "Non-Target Accuracy: 1.0\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 1.0\n",
      "Non-Target F1 Score: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lhinkson/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall': {'Accuracy': 0.89,\n",
       "  'Precision': 0.0,\n",
       "  'Recall': 0.0,\n",
       "  'F1': 0.0,\n",
       "  'ROC_AUC': 0.5},\n",
       " 'Target': {'Accuracy': 0.0, 'Precision': 0.0, 'Recall': 0.0, 'F1': 0.0},\n",
       " 'Non-Target': {'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1': 1.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exl.get_metrics(results, should_print=True, detailed = False, \n",
    "#                 label_col=\"y_true\", score_col=\"predicted_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Batch Loader to Enable Larger Dataset Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv(\"jigsaw_toxic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full['label'] = train_full.target.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full['label_multiclass'] = train_full.target.apply(\n",
    "    lambda x: \"very toxic\" if x > 0.6 else \"toxic\" if 0.4 < x <= 0.6 else \"not_toxic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training samples at proportion 0.2\n"
     ]
    }
   ],
   "source": [
    "train_sample, val_set, test_set = exl.get_samples(train_full, proportion=0.2, \n",
    "                                                  train_test_ratio=(1-test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288740, 47) (181156, 47) (180019, 47)\n"
     ]
    }
   ],
   "source": [
    "print(train_sample.shape, val_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samples = val_set.sample( n=math.ceil(len(train_sample)*test_ratio), random_state=1008 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57748, 47)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Attribution: https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\n",
    "from torchtext.data import Field, Dataset, Example\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "        examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "            string is a field name, and the Field is the associated field.\n",
    "        filter_pred (callable or None): use only exanples for which\n",
    "            filter_pred(example) is true, or use all examples if None.\n",
    "            Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "                \n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "\n",
    "        for key, field in fields.items():\n",
    "#             print(key)\n",
    "#             print(field)\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text, stop_ws=exl.stops, stemmer=None, str_output=False):\n",
    "\n",
    "    t = text.replace(\"-\", \" \").split(\" \")\n",
    "    t = [w.strip(string.punctuation) for w in t]\n",
    "\n",
    "    if stop_ws:\n",
    "        t = [w.lower() for w in t if w not in stop_ws]\n",
    "\n",
    "    if stemmer:\n",
    "        t = [stemmer.stem(w) for w in t]\n",
    "\n",
    "    if str_output:\n",
    "        return ' '.join(t)\n",
    "    else:\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer, lower=True, init_token = \"<sos>\", \n",
    "             eos_token = \"<eos>\", batch_first=True)\n",
    "LABEL = data.Field(sequential=False, unk_token=None, dtype=torch.float, is_target=True)\n",
    "# LABEL = data.Field(sequential=False, unk_token=None, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DataFrameDataset(train_sample, fields = { 'label' : LABEL, 'comment_text' : TEXT })\n",
    "valid_ds = DataFrameDataset(val_samples, fields = { 'label' : LABEL, 'comment_text' : TEXT })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds2 = DataFrameDataset(train_sample, fields = { 'label_multiclass' : LABEL, 'comment_text' : TEXT })\n",
    "valid_ds2 = DataFrameDataset(val_samples, fields = { 'label_multiclass' : LABEL, 'comment_text' : TEXT })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_ds, max_size=25000)\n",
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi['leave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[434])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution: Adapted from https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95\n",
    "import torch\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "\n",
    "global max_text_in_batch\n",
    "\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_text_in_batch\n",
    "    if count == 1:\n",
    "        max_text_in_batch = 0\n",
    "    max_text_in_batch = max(max_text_in_batch, len(new.comment_text) + 2)\n",
    "    text_elements = count * max_text_in_batch\n",
    "    return text_elements\n",
    "\n",
    "\n",
    "class EfficientIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': <torchtext.data.field.Field at 0x7f7c855a2a20>,\n",
       " 'comment_text': <torchtext.data.field.Field at 0x7f7c855a2ac8>}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': <torchtext.data.field.Field at 0x7f7c855a2a20>,\n",
       " 'comment_text': <torchtext.data.field.Field at 0x7f7c855a2ac8>}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 25004\n"
     ]
    }
   ],
   "source": [
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "# print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P ../ \"http://nlp.stanford.edu/data/glove.840B.300d.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip \"../glove.840B.300d.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(train_ds, batch_size=20, \\\n",
    "sort_key=lambda x: len(x.comment_text), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   23, 3085,  ...,    1,    1,    1],\n",
      "        [   2,   68,  617,  ...,    1,    1,    1],\n",
      "        [   2,  428, 1508,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,  404, 1091,  ...,    1,    1,    1],\n",
      "        [   2,   36,  117,  ...,    1,    1,    1],\n",
      "        [   2,    4,   17,  ...,  894,    8,    3]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = EfficientIterator(\n",
    "    train_ds, batch_size=1300, \n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    repeat=False, sort_key= lambda x: len(x.comment_text), batch_size_fn=batch_size_fn, \n",
    "    train=True, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(train_ds, batch_size=1300, \\\n",
    "sort_key=lambda x: len(x.comment_text), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = EfficientIterator(\n",
    "    valid_ds, batch_size=1300, \n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    repeat=False, sort_key= lambda x: len(x.comment_text), batch_size_fn=batch_size_fn, \n",
    "    train=True, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   36,  565,  ...,    1,    1,    1],\n",
      "        [   2, 5079,  705,  ...,    1,    1,    1],\n",
      "        [   2, 4821, 1623,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,  135, 1005,  ...,    1,    1,    1],\n",
      "        [   2,    6, 1633,  ...,    1,    1,    1],\n",
      "        [   2,  782,  187,  ...,    1,    1,    1]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.comment_text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,    25,     9,  ...,    37,  1324,     3],\n",
      "        [    2,   436,  2040,  ...,   793,  7787,     3],\n",
      "        [    2,  2629,  1109,  ...,     0,  3532,     3],\n",
      "        ...,\n",
      "        [    2,     4,    12,  ...,   312,    70,     3],\n",
      "        [    2,    11,   255,  ...,    24,   159,     3],\n",
      "        [    2,    80, 19986,  ...,  5688,   141,     3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_iter))\n",
    "print(batch.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, batch_size=1,\n",
    "                 embed_dim=6, weight_decay=0, optimizer_fcn='Adam',\n",
    "                 learning_rate=1e-3, num_layers=2, dropout=0.05, num_classes=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        nn.Module.__init__(self)\n",
    "#         TextData.__init__(self, X_data)\n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        self.output_dim = num_classes\n",
    "        self.loss_fcn = nn.NLLLoss()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.highest_f1 = -math.inf\n",
    "\n",
    "        # Layer 1: Embedding Layer\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "\n",
    "        # Layer 2: LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size = self.embed_dim, hidden_size = self.hidden_dim,\n",
    "                            num_layers = self.num_layers, dropout = self.dropout, \n",
    "                            batch_first=True)\n",
    "\n",
    "        # Layer 3 (Output Layer): Linear\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        # define optimizer\n",
    "        if optimizer_fcn == 'Adam':\n",
    "            self.optimizer = optim.Adam(params=self.parameters(),\n",
    "                                                 weight_decay=self.weight_decay,\n",
    "                                                 lr=self.learning_rate)\n",
    "        elif optimizer_fcn == 'RMSprop':\n",
    "            self.optimizer = optim.RMSprop(params=self.parameters(),\n",
    "                                                 weight_decay=self.weight_decay,\n",
    "                                                 lr=self.learning_rate)\n",
    "        elif optimizer_fcn == 'SDG':\n",
    "            self.optimizer = optim.SGD(params=self.parameters(),\n",
    "                                                 weight_decay=self.weight_decay,\n",
    "                                                 lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "\n",
    "        embed_out = self.embedding(input_seq)\n",
    "\n",
    "        lstm_out, (hn, cn) = self.lstm(embed_out)\n",
    "\n",
    "        out = F.log_softmax(self.linear(hn), dim=self.output_dim)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 6\n",
    "hist_lstm = np.zeros(NUM_EPOCHS)\n",
    "model_name=\"toy_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMModel(hidden_dim=50, num_layers=1, embed_dim=50, \n",
    "                       batch_size=train_iter.batch_size,\n",
    "                       dropout=0, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    lstm_model = lstm_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 1., 0.])\n",
      "embed torch.Size([1300, 118, 50])\n",
      "hn torch.Size([1, 1300, 50])\n",
      "lstm_out torch.Size([1300, 118, 50])\n",
      "cn torch.Size([1, 1300, 50])\n",
      "original tensor([[[-0.7926, -0.6027],\n",
      "         [-0.8277, -0.5745],\n",
      "         [-0.7621, -0.6286],\n",
      "         ...,\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.7926, -0.6027],\n",
      "         [-0.7133, -0.6734],\n",
      "         [-0.6564, -0.7313],\n",
      "         ...,\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.7926, -0.6027],\n",
      "         [-0.7413, -0.6472],\n",
      "         [-0.7550, -0.6349],\n",
      "         ...,\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7926, -0.6027],\n",
      "         [-0.7989, -0.5975],\n",
      "         [-0.7720, -0.6201],\n",
      "         ...,\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.7926, -0.6027],\n",
      "         [-0.7735, -0.6188],\n",
      "         [-0.6894, -0.6969],\n",
      "         ...,\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762],\n",
      "         [-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.7926, -0.6027],\n",
      "         [-0.7491, -0.6402],\n",
      "         [-0.7138, -0.6729],\n",
      "         ...,\n",
      "         [-0.7095, -0.6770],\n",
      "         [-0.7097, -0.6769],\n",
      "         [-0.7098, -0.6768]]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "torch.Size([1300, 118, 2])\n",
      "view -1 tensor([-0.7926, -0.6027, -0.8277,  ..., -0.6769, -0.7098, -0.6768],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([306800])\n",
      "unsqueeze 1 tensor([[[[-0.7926, -0.6027],\n",
      "          [-0.8277, -0.5745],\n",
      "          [-0.7621, -0.6286],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]]],\n",
      "\n",
      "\n",
      "        [[[-0.7926, -0.6027],\n",
      "          [-0.7133, -0.6734],\n",
      "          [-0.6564, -0.7313],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]]],\n",
      "\n",
      "\n",
      "        [[[-0.7926, -0.6027],\n",
      "          [-0.7413, -0.6472],\n",
      "          [-0.7550, -0.6349],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.7926, -0.6027],\n",
      "          [-0.7989, -0.5975],\n",
      "          [-0.7720, -0.6201],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]]],\n",
      "\n",
      "\n",
      "        [[[-0.7926, -0.6027],\n",
      "          [-0.7735, -0.6188],\n",
      "          [-0.6894, -0.6969],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]]],\n",
      "\n",
      "\n",
      "        [[[-0.7926, -0.6027],\n",
      "          [-0.7491, -0.6402],\n",
      "          [-0.7138, -0.6729],\n",
      "          ...,\n",
      "          [-0.7095, -0.6770],\n",
      "          [-0.7097, -0.6769],\n",
      "          [-0.7098, -0.6768]]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1300, 1, 118, 2])\n",
      "unsqueeze 0 tensor([[[[-0.7926, -0.6027],\n",
      "          [-0.8277, -0.5745],\n",
      "          [-0.7621, -0.6286],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]],\n",
      "\n",
      "         [[-0.7926, -0.6027],\n",
      "          [-0.7133, -0.6734],\n",
      "          [-0.6564, -0.7313],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]],\n",
      "\n",
      "         [[-0.7926, -0.6027],\n",
      "          [-0.7413, -0.6472],\n",
      "          [-0.7550, -0.6349],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7926, -0.6027],\n",
      "          [-0.7989, -0.5975],\n",
      "          [-0.7720, -0.6201],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]],\n",
      "\n",
      "         [[-0.7926, -0.6027],\n",
      "          [-0.7735, -0.6188],\n",
      "          [-0.6894, -0.6969],\n",
      "          ...,\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762],\n",
      "          [-0.7104, -0.6762]],\n",
      "\n",
      "         [[-0.7926, -0.6027],\n",
      "          [-0.7491, -0.6402],\n",
      "          [-0.7138, -0.6729],\n",
      "          ...,\n",
      "          [-0.7095, -0.6770],\n",
      "          [-0.7097, -0.6769],\n",
      "          [-0.7098, -0.6768]]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1, 1300, 118, 2])\n",
      "labels tensor([0., 0., 0.,  ..., 0., 1., 0.], device='cuda:0')\n",
      "torch.Size([1300])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (1300, 2), got torch.Size([1300])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-01768b434da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 1881\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (1300, 2), got torch.Size([1300])"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "last_mean_error = -math.inf\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0\n",
    "    for x, y in train_iter:\n",
    "#         print(x)\n",
    "#         print(x.size())\n",
    "        print(y)\n",
    "#         print(y.size()) \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda() \n",
    "            y = y.cuda()\n",
    "            \n",
    "        lstm_model.optimizer.zero_grad()\n",
    "        \n",
    "        embed_out = lstm_model.embedding(x)\n",
    "\n",
    "        print(\"embed\", embed_out.size())\n",
    "        lstm_out, (hn, cn) = lstm_model.lstm(embed_out)\n",
    "        print(\"hn\", hn.size())\n",
    "        print(\"lstm_out\", lstm_out.size())\n",
    "        print(\"cn\", cn.size())\n",
    "\n",
    "#         out = F.log_softmax(lstm_model.linear(hn), dim=lstm_model.output_dim)\n",
    "        out = F.log_softmax(lstm_model.linear(lstm_out), dim=lstm_model.output_dim)\n",
    "        print(\"original\", out)\n",
    "        print(out.size())\n",
    "        print(\"view -1\", out.view(-1))\n",
    "        print(out.view(-1).size())\n",
    "        print(\"unsqueeze 1\", out.unsqueeze(1))\n",
    "        print(out.unsqueeze(1).size())\n",
    "        print(\"unsqueeze 0\", out.unsqueeze(0))\n",
    "        print(out.unsqueeze(0).size())\n",
    "        print(\"labels\", y)\n",
    "        print(y.size())\n",
    "        loss = lstm_model.loss_fcn(out, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        thresholds= {\n",
    "                5000: 1000,\n",
    "                1000: 100,\n",
    "                100: 10,\n",
    "                20: 5,\n",
    "                10: 3\n",
    "            }\n",
    "        \n",
    "        print_at = 2\n",
    "        if num_epochs in  thresholds.keys():\n",
    "            print_at = thresholds[num_epochs]\n",
    "        # print results for every few epochs\n",
    "        if epoch % print_at == 0:\n",
    "            print(f\"Epoch {epoch}, Negative Log Linear Loss: {running_loss}\")\n",
    "            hist_lstm[epoch] = loss.item()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if np.mean(np.abs(loss.item())) < last_mean_error:\n",
    "                    print(f\"Delta after {epoch} iterations: {np.mean(np.abs(loss.item()))}\")\n",
    "                    last_mean_error = np.mean(np.abs(loss.item()))\n",
    "                else:\n",
    "                    if last_mean_error > -math.inf:\n",
    "                        print(f\"Break: {np.mean(np.abs(loss.item()))} > {last_mean_error}\")\n",
    "                        break\n",
    "        print()\n",
    "        print(\"Starting Evaluation\")                    \n",
    "#         model_f1, results_df = self.evaluate_classifier(test_X, test_y, text_col=text_col)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for text, labels in val_iter:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                if torch.cuda.is_available():\n",
    "                    text = text.cuda() \n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                lstm_model.optimizer.zero_grad()\n",
    "\n",
    "                embed_out = lstm_model.embedding(text)\n",
    "\n",
    "                lstm_out, (hn, cn) = lstm_model.lstm(embed_out)\n",
    "\n",
    "                preds = F.log_softmax(lstm_model.linear(hn), dim=lstm_model.output_dim)\n",
    "                print(preds)\n",
    "                print(preds.size())\n",
    "                print(labels)\n",
    "                print(labels.size)\n",
    "                indices = torch.argmax(preds, dim=0)\n",
    "                print(indices)\n",
    "\n",
    "                _, predicted = torch.max(preds.data, 1)\n",
    "                print(predicted)\n",
    "                correct += float((predicted == labels).sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
