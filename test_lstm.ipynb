{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_lstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "b6shNJdp1GuO",
        "2QaIVi9O1daj",
        "gcnufZwcNRJ3",
        "-o8nY8D9OW4n"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcENPI2NQ1rW",
        "colab_type": "text"
      },
      "source": [
        "# Identifying Hate Speech in Social Media Comments: PyTorch LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4eDhtxDQ7Ey",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zx9y7jLffJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import ssl\n",
        "import json\n",
        "import nltk\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as tud\n",
        "from collections import Counter, OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8BYwZSkIswo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "warnings.filterwarnings(action='once')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZBI0yauX7w",
        "colab_type": "code",
        "outputId": "5b7632ca-fa8f-47ef-c142-d472166e5ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKsJchrPuLYE",
        "colab_type": "code",
        "outputId": "6ab091c8-e2bf-4c89-d283-e8975c1ba250",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a0f92a5-6df2-487e-a075-e901fa70e836\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9a0f92a5-6df2-487e-a075-e901fa70e836\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving exec_lstm.py to exec_lstm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuaHFOJxffJ0",
        "colab_type": "code",
        "outputId": "93e5761a-8fc9-4ecb-93b5-0c9bb04a168c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "import exec_lstm as exl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/content/exec_lstm.py\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    from nltk.corpus import stopwords\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m default 'except:' must be last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_CtPMsJPe69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFYlzfkffJ4",
        "colab_type": "code",
        "outputId": "27d64a42-55a5-435f-8b18-061b178f7517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2CoPnulZEyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e830bc6f-0c39-4174-b879-e081b1c80e9a"
      },
      "source": [
        "# import importlib\n",
        "# import google\n",
        "# importlib.reload(google.colab.auth)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'google.colab.auth' from '/usr/local/lib/python3.6/dist-packages/google/colab/auth.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms0t4XSSHIsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f82a53a6-44ad-44ea-bf30-c339236a7b1a"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google/colab/auth.py:141: ResourceWarning: unclosed <ssl.SSLSocket fd=83, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 37472), raddr=('74.125.135.84', 443)>\n",
            "  if _check_adc():\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnd-yCkXIAAR",
        "colab_type": "code",
        "outputId": "9e7636ad-d34c-441b-892a-b34e062ba059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "!pip install gcsfs"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/19/68ab4e6570a7882698058be8ecf1b195b0b784b838ac1b0ea82c422c0f5a/gcsfs-0.2.2.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.5)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.2.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.0.1)\n",
            "Building wheels for collected packages: gcsfs\n",
            "  Building wheel for gcsfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/0f/b9/5bc5222756d121ccace51ab3084a1c733380908a4e2f939038\n",
            "Successfully built gcsfs\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/google/colab/_pip.py:87: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.6/dist-packages/gcsfs-0.2.2.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2mbxM4gHnqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "94fe2196-f3f7-4714-929f-4d462d284609"
      },
      "source": [
        "import gcsfs\n",
        "train_full = pd.read_csv('gs://no-hate/train.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isOUNQIaffKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_full['label'] = train_full.target.apply(lambda x: 1 if x > 0.5 else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAS5oWmwffKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ratio = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSmvany6N4BH",
        "colab_type": "text"
      },
      "source": [
        "## Housekeeping and Variable Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0V-qB-7cpTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ_0Bo0bomng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "608b2852-4fce-415c-ce21-a2987a34f085"
      },
      "source": [
        "project_id = 'tribal-monolith-242216'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIMKCRNboFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def send_to_bucket(filename, bucket_name=\"no-hate\", directory=None):\n",
        "    if directory:\n",
        "        !gsutil cp /content/{filename} gs://{bucket_name}/{directory}/\n",
        "    else:\n",
        "        !gsutil cp /content/{filename} gs://{bucket_name}/\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86RCZW-1pUOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# send_to_bucket(filename='20pct_imbalanced_model_state.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp4rsgW_sYoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "# import cloudstorage\n",
        "import gcsfs\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "\n",
        "def pickle_to_gcs(df, filename, bucket_name=\"no-hate\", directory=None):\n",
        "    pickle_buffer = io.BytesIO()\n",
        "    fs = gcsfs.GCSFileSystem(project=project_id)\n",
        "    df.to_pickle(filename)\n",
        "    \n",
        "    if directory:\n",
        "        directory = directory + \"/\"\n",
        "    else:\n",
        "        directory = \"\"\n",
        "    \n",
        "    with fs.open(f\"{bucket_name}/{directory}{filename}\", \"wb\") as handle:    \n",
        "        pickle.dump(df, handle)\n",
        "        \n",
        "    \n",
        "def load_pickle_from_gcs(filename, bucket_name=\"no-hate\",  directory=None):\n",
        "    fs = gcsfs.GCSFileSystem(project=project_id) \n",
        "    \n",
        "    if not directory:\n",
        "        directory = directory + \"/\"\n",
        "    else:\n",
        "        directory = \"\"\n",
        "        \n",
        "    with fs.open(f\"{bucket_name}/{directory}{filename}\", \"rb\") as handle:\n",
        "        df = pickle.load(handle)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HSe4sRxuDkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pickle_to_gcs(test_set, '20pct_test_set.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gugtkx87zjTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(test_set.shape, test_set.comment_text.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCyoLsY0zDFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check = load_pickle_from_gcs('20pct_test_set.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwzOEfL1zgAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(check.shape, check.comment_text.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIw-KDeBFln9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check Available RAM\n",
        "\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#     process = psutil.Process(os.getpid())\n",
        "#     print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGRp_AzPF5N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear RAM\n",
        "\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avoL6-pwffKJ",
        "colab_type": "text"
      },
      "source": [
        "## Creating Batch Loader to Enable Larger Dataset Training\n",
        "\n",
        "Use 20% data partition while building batch loader for LSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6shNJdp1GuO",
        "colab_type": "text"
      },
      "source": [
        "### Create Batch Loader Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYmI6n9ZffKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_full = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9SFTFjqffKS",
        "colab_type": "code",
        "outputId": "ab5f2be0-f93d-4a69-f4fe-15f4ede1c133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_set, val_set, test_set = exl.get_samples(train_full, proportion=0.2, \n",
        "                                                  train_test_ratio=(1-test_ratio))"
      ],
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieving training samples at proportion 0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHD64__LffKY",
        "colab_type": "code",
        "outputId": "4ae5a407-4a5e-4a0a-f9ec-d178f6d158fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_sample.shape, val_set.shape, test_set.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288752, 47) (180419, 47) (180694, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AZgVpVX2bP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad29fd78-2f81-47e1-f60e-8954790d449e"
      },
      "source": [
        "train_sample.loc[train_sample.comment_text != ''].shape"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(288752, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gn6znXcffKU",
        "colab_type": "code",
        "outputId": "533e5c7f-5313-403d-e1cd-739f6b9ff882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "train_sample.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>identity_attack</th>\n",
              "      <th>insult</th>\n",
              "      <th>threat</th>\n",
              "      <th>asian</th>\n",
              "      <th>atheist</th>\n",
              "      <th>bisexual</th>\n",
              "      <th>black</th>\n",
              "      <th>buddhist</th>\n",
              "      <th>christian</th>\n",
              "      <th>female</th>\n",
              "      <th>heterosexual</th>\n",
              "      <th>hindu</th>\n",
              "      <th>homosexual_gay_or_lesbian</th>\n",
              "      <th>intellectual_or_learning_disability</th>\n",
              "      <th>jewish</th>\n",
              "      <th>latino</th>\n",
              "      <th>male</th>\n",
              "      <th>muslim</th>\n",
              "      <th>other_disability</th>\n",
              "      <th>other_gender</th>\n",
              "      <th>other_race_or_ethnicity</th>\n",
              "      <th>other_religion</th>\n",
              "      <th>other_sexual_orientation</th>\n",
              "      <th>physical_disability</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>transgender</th>\n",
              "      <th>white</th>\n",
              "      <th>created_date</th>\n",
              "      <th>publication_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>sexual_explicit</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "      <th>label</th>\n",
              "      <th>label_multiclass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1250941</th>\n",
              "      <td>5643809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1980s USA routs USSR. Winner - Iran. No more e...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-07-23 15:01:56.128046+00</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>358404</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>not_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279216</th>\n",
              "      <td>584484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>I write during election day as ballots are sti...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-11-08 17:30:19.184759+00</td>\n",
              "      <td>53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150883</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>not_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880431</th>\n",
              "      <td>5197854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>My 911 will never hit the resale market . Non-...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-04-30 16:06:09.307109+00</td>\n",
              "      <td>54</td>\n",
              "      <td>5189868.0</td>\n",
              "      <td>330092</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>not_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146876</th>\n",
              "      <td>421727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>\"You can`t fool all the people, all the time.....</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-08-08 17:21:33.854424+00</td>\n",
              "      <td>21</td>\n",
              "      <td>420995.0</td>\n",
              "      <td>143205</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>not_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1205377</th>\n",
              "      <td>5588980</td>\n",
              "      <td>0.626667</td>\n",
              "      <td>This man here is a big fan of sexual assault!</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017-07-13 22:36:36.407757+00</td>\n",
              "      <td>102</td>\n",
              "      <td>5588786.0</td>\n",
              "      <td>355090</td>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>6</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>very toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id    target  ... label  label_multiclass\n",
              "1250941  5643809  0.000000  ...     0         not_toxic\n",
              "279216    584484  0.000000  ...     0         not_toxic\n",
              "880431   5197854  0.000000  ...     0         not_toxic\n",
              "146876    421727  0.000000  ...     0         not_toxic\n",
              "1205377  5588980  0.626667  ...     1        very toxic\n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abjEy-Zd57Mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bca38997-e8ed-4b1d-9350-ab624ced79a5"
      },
      "source": [
        "# train_drop = train_sample[train_sample.comment_text.apply(exl.tokenizer).apply(len) <= 0].index\n",
        "# train_drop"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([  59512, 1793038, 1184410, 1580427,  724850,  734725, 1557245,\n",
              "            1342916, 1382702, 1211128, 1229590, 1678594,  575017,  262428,\n",
              "             889620,  912764,  247641, 1121494,  697462, 1397745, 1211128,\n",
              "             856821, 1741764, 1516224, 1239748, 1089317,  823409,   35976,\n",
              "             633848, 1522947, 1312149,  575017,  579673, 1211512,  751400,\n",
              "             298847, 1325795,  955811, 1726165,  833213, 1522947,  422750,\n",
              "            1520125, 1434204, 1387919, 1073797, 1520125, 1239748,  134359,\n",
              "             301923,  777401,   91317,  512414,  603073,  304749, 1068988,\n",
              "             973659,  813976,  925937,  503808, 1483813, 1245547],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w0GAP6L6P90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_sample = train_sample.drop(train_drop, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQd7VXHlffKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_samples = val_set.sample( n=math.ceil(len(train_sample)*test_ratio), random_state=1008 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJngfdLJffKe",
        "colab_type": "code",
        "outputId": "480f977b-6e77-43e9-ab76-c1b4cf35afc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_samples.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57751, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwD-mIMV53lM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "532cc167-c85a-4e06-b70a-9e13d9b05587"
      },
      "source": [
        "# val_drop = val_samples[val_samples.comment_text.apply(exl.tokenizer).apply(len) <= 0].index\n",
        "# val_drop"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([1142416,  465369, 1108078,  239717,  545435, 1785002, 1439732,\n",
              "            1431356, 1670979,  674520,  134403, 1033370, 1049276,  296895,\n",
              "             672091, 1158704,     316,  609516],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYWrlBF86eu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# val_samples = val_samples.drop(val_drop, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJMdjtqFwf8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_samples = test_set.sample( n=math.ceil(len(train_sample)*test_ratio), random_state=1008 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC6h9x0w5du4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8df7f5de-21e0-4060-abeb-1c8a8e92e582"
      },
      "source": [
        "# test_drop = test_samples[test_samples.comment_text.apply(exl.tokenizer).apply(len) <= 0].index\n",
        "# test_drop"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([1622847, 1394777,  791534,  461805, 1075192, 1289137, 1651804,\n",
              "            1178279, 1569896,   46991,  969825],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddbNYd9C6ieq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_samples = test_samples.drop(test_drop, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhJ-qFHp1RTR",
        "colab_type": "text"
      },
      "source": [
        "### Data Loader Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_u3VHHsffKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# H/T for the torchtext dataframe-based-Dataset hack to: \n",
        "# https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\n",
        "from torchtext.data import Field, Dataset, Example\n",
        "import pandas as pd\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "        Create a dataset from a pandas dataframe of examples and Fields\n",
        "        Arguments:\n",
        "        examples pd.DataFrame: DataFrame of examples\n",
        "            fields {str: Field}: The Fields to use in this tuple. The\n",
        "            string is a field name, and the Field is the associated field.\n",
        "        filter_pred (callable or None): use only exanples for which\n",
        "            filter_pred(example) is true, or use all examples if None.\n",
        "            Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]\n",
        "\n",
        "                \n",
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "\n",
        "        for key, field in fields.items():\n",
        "#             print(key)\n",
        "#             print(field)\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWX0b8xSffKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text, stop_ws=exl.stops, stemmer=None, str_output=False):\n",
        "\n",
        "    t = text.replace(\"-\", \" \").split(\" \")\n",
        "    t = [w.strip(string.punctuation) for w in t]\n",
        "\n",
        "    if stop_ws:\n",
        "        t = [w.lower() for w in t if w not in stop_ws]\n",
        "\n",
        "    if stemmer:\n",
        "        t = [stemmer.stem(w) for w in t]\n",
        "\n",
        "    if t == []:\n",
        "        return ['<blank>']\n",
        "    if str_output:\n",
        "        return ' '.join(t)\n",
        "    else:\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QaIVi9O1daj",
        "colab_type": "text"
      },
      "source": [
        "### Data Loader Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ZraRaGffKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer, lower=True, include_lengths = True)\n",
        "LABEL = Field(sequential=False, unk_token=None, \n",
        "              dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tau-zbnLffKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = DataFrameDataset(train_sample, fields = {'label' : LABEL, \n",
        "                                                    'comment_text': TEXT})\n",
        "valid_ds = DataFrameDataset(val_samples, fields = {'label' : LABEL, \n",
        "                                                   'comment_text': TEXT})\n",
        "test_ds = DataFrameDataset(test_samples, fields = { 'label' : LABEL, \n",
        "                                                   'comment_text' : TEXT})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuzua6h9ffKx",
        "colab_type": "code",
        "outputId": "b3f3b62b-381e-46e5-8edb-c2149b70d3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_ds.fields"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment_text': <torchtext.data.field.Field at 0x7f241e3de0b8>,\n",
              " 'label': <torchtext.data.field.Field at 0x7f241e3de0f0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePOPjdgVffK0",
        "colab_type": "code",
        "outputId": "18506e13-91a2-44f1-bb94-608ab107c3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "valid_ds.fields"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment_text': <torchtext.data.field.Field at 0x7f241e3de0b8>,\n",
              " 'label': <torchtext.data.field.Field at 0x7f241e3de0f0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bneQDCt3ffKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_ds, max_size=25000, \n",
        "#                  vectors = \"glove.840B.300d\",\n",
        "                 vectors = \"glove.6B.200d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiIC_VLaffK2",
        "colab_type": "code",
        "outputId": "e0a687b8-32aa-4539-c218-4fca3a57ae20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
        "# print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())"
      ],
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(TEXT.vocab) 25002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8EMXlNfffKp",
        "colab_type": "code",
        "outputId": "4dc5fc4d-82f4-4102-869e-498f9f194157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.stoi['hope'])"
      ],
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijUOcvskffKt",
        "colab_type": "code",
        "outputId": "013a586a-e348-41e7-8fea-99c25c8cdc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[198])"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMXfL_XYffKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Attribution: Adapted from https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95\n",
        "# import torch\n",
        "# from torchtext import data\n",
        "# import numpy as np\n",
        "\n",
        "# global max_text_in_batch\n",
        "\n",
        "# def batch_size_fn(new, count, sofar):\n",
        "#     \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "#     global max_text_in_batch\n",
        "#     if count == 1:\n",
        "#         max_text_in_batch = 0\n",
        "#     max_text_in_batch = max(max_text_in_batch, len(new.comment_text) + 2)\n",
        "#     text_elements = count * max_text_in_batch\n",
        "#     return text_elements\n",
        "\n",
        "\n",
        "# class EfficientIterator(data.Iterator):\n",
        "#     def create_batches(self):\n",
        "#         if self.train:\n",
        "#             def pool(d, random_shuffler):\n",
        "#                 for p in data.batch(d, self.batch_size * 100):\n",
        "#                     p_batch = data.batch(\n",
        "#                         sorted(p, key=self.sort_key),\n",
        "#                         self.batch_size, self.batch_size_fn)\n",
        "#                     for b in random_shuffler(list(p_batch)):\n",
        "#                         yield b\n",
        "#             self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "#         else:\n",
        "#             self.batches = []\n",
        "#             for b in data.batch(self.data(), self.batch_size,\n",
        "#                                           self.batch_size_fn):\n",
        "#                 self.batches.append(sorted(b, key=self.sort_key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZD5ksVPffK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VOCAB_SIZE = len(TEXT.vocab)\n",
        "BATCH_SIZE = 1300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH5Zmse2xGNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "    (train_ds, valid_ds, test_ds), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.comment_text),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4PAzMNUqs4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cf6871c-3cda-46fb-a6d8-5af9e85ec717"
      },
      "source": [
        "device"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMsBFkLwffK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_iter = EfficientIterator(\n",
        "#     train_ds, batch_size=1300, \n",
        "#     device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "#     repeat=False, sort_key= lambda x: len(x.comment_text), batch_size_fn=batch_size_fn, \n",
        "#     train=True, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFCnCBlmffK-",
        "colab_type": "code",
        "outputId": "cdc69502-1e1d-4625-cd13-d535af7c2209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "batch = next(iter(train_iter))\n",
        "print(batch.label)\n",
        "print(batch.label.size())\n",
        "print(batch.comment_text)\n",
        "print(batch.comment_text[0].size())"
      ],
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
            "torch.Size([1300])\n",
            "(tensor([[    0,     0,   133,  ...,   952,   143,  4746],\n",
            "        [    8,    61, 16130,  ...,   555,    64,     3],\n",
            "        [22173,  1299,  3039,  ...,   230,  3614,   691],\n",
            "        ...,\n",
            "        [    0,    77,   110,  ...,     7,    80, 17413],\n",
            "        [10131,  1000,    62,  ...,  5331,  3881,  3139],\n",
            "        [ 2852,  1319,  3039,  ...,  3984,  8353,  6362]], device='cuda:0'), tensor([9, 9, 9,  ..., 9, 9, 9], device='cuda:0'))\n",
            "torch.Size([9, 1300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CkLGTRQz9Rj",
        "colab_type": "code",
        "outputId": "58862ca7-9f1e-4e99-8e12-3ac12a96c78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "val_batch = next(iter(val_iter))\n",
        "print(val_batch.label)\n",
        "print(val_batch.label.size())\n",
        "print(val_batch.comment_text)\n",
        "print(val_batch.comment_text[0].size())"
      ],
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
            "torch.Size([1300])\n",
            "(tensor([[  70,   31,    0,  ..., 2697, 2192, 1433],\n",
            "        [  57, 5855,    0,  ...,    1,    1,    1]], device='cuda:0'), tensor([2, 2, 2,  ..., 1, 1, 1], device='cuda:0'))\n",
            "torch.Size([2, 1300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXnBVtcO0Ss0",
        "colab_type": "code",
        "outputId": "c3ca2984-299b-4b95-c711-7f35d7496667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "test_batch = next(iter(test_iter))\n",
        "print(test_batch.label)\n",
        "print(test_batch.label.size())\n",
        "print(test_batch.comment_text)\n",
        "print(test_batch.comment_text[0].size())"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
            "torch.Size([1300])\n",
            "(tensor([[ 1197, 16468,    28,  ...,  2371,     0,   890],\n",
            "        [ 4804,    28,  1190,  ...,     1,     1,     1]], device='cuda:0'), tensor([2, 2, 2,  ..., 1, 1, 1], device='cuda:0'))\n",
            "torch.Size([2, 1300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOBIYlqqffLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# val_iter = EfficientIterator(\n",
        "#     valid_ds, batch_size=1300, \n",
        "#     device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "#     repeat=False, sort_key= lambda x: len(x.comment_text), batch_size_fn=batch_size_fn, \n",
        "#     train=True, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljuHEYXjz9kr",
        "colab_type": "text"
      },
      "source": [
        "### Integrate Batch Loader into Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m7TpXvUffLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, pad_idx, batch_size=1,\n",
        "                 embed_dim=6, weight_decay=0, optimizer_fcn='Adam',\n",
        "                 learning_rate=1e-3, num_layers=2, dropout=0.05, \n",
        "                 num_classes=1, bidirectional=True):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        nn.Module.__init__(self)\n",
        "#         TextData.__init__(self, X_data)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dropout = dropout\n",
        "        self.output_dim = num_classes\n",
        "        self.loss_fcn = nn.NLLLoss()\n",
        "        self.weight_decay = weight_decay\n",
        "        self.learning_rate = learning_rate\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "        # Layer 1: Embedding Layer\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embed_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # Layer 2: LSTM Layer\n",
        "        self.lstm = nn.LSTM(input_size = self.embed_dim, \n",
        "                            hidden_size = self.hidden_dim,\n",
        "                            num_layers = self.num_layers, \n",
        "                            dropout = self.dropout,\n",
        "                            bidirectional=bidirectional) \n",
        "#                             batch_first=True)\n",
        "\n",
        "        # Layer 3 (Output Layer): Linear\n",
        "        self.linear = nn.Linear(self.hidden_dim * 2, self.output_dim)\n",
        "    \n",
        "        # Dropout Layer  \n",
        "        self.dropout_layer = nn.Dropout(self.dropout)\n",
        "\n",
        "        # define optimizer\n",
        "        if optimizer_fcn == 'Adam':\n",
        "            self.optimizer = optim.Adam(params=self.parameters(),\n",
        "                                                 weight_decay=self.weight_decay,\n",
        "                                                 lr=self.learning_rate)\n",
        "        elif optimizer_fcn == 'RMSprop':\n",
        "            self.optimizer = optim.RMSprop(params=self.parameters(),\n",
        "                                                 weight_decay=self.weight_decay,\n",
        "                                                 lr=self.learning_rate)\n",
        "        elif optimizer_fcn == 'SDG':\n",
        "            self.optimizer = optim.SGD(params=self.parameters(),\n",
        "                                                 weight_decay=self.weight_decay,\n",
        "                                                 lr=self.learning_rate)\n",
        "            \n",
        "\n",
        "    def forward(self, input_seq, input_len):\n",
        "        # input_seq shape is [batch_max_input_len, batch_size]\n",
        "        embed_out = self.embedding(input_seq)\n",
        "        embed_out = self.dropout_layer(embed_out)\n",
        "\n",
        "        # embed_out shape is [batch_max_input_len, batch_size, embed_dim]\n",
        "\n",
        "        \n",
        "        # tell LSTM layer to focus on non-padded elements by packing embeddings\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embed_out, input_len)\n",
        "        \n",
        "        packed_lstm_out, (hn, cn) = self.lstm(packed_embedded)\n",
        "        # hn shape is [num_layers * num_directions, batch_size, hidden_dim]\n",
        "        \n",
        "        # unpack sequences into tensors if need them\n",
        "        # out, out_len = nn.utils.rnn.pad_packed_sequence(packed_lstm_out)\n",
        "        # out shape is [batch_max_input_len, batch_size, hidden_dim * num directions]\n",
        "        \n",
        "        #concat final forward and backward hidden layers to apply any dropout\n",
        "        hn = self.dropout_layer(torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1))\n",
        "        # hn shape is [batch size, hid dim * num directions]\n",
        "        \n",
        "#         out = F.log_softmax(self.linear(hn.squeeze(0)), dim=self.output_dim) \n",
        "        out = F.log_softmax(self.linear(hn), dim=1)\n",
        "        # out shape is [batch_size, outpu_dim]\n",
        "        \n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJW8CophffLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_clf(model, iterator):\n",
        "    running_loss = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_nontarget_recall = 0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "#         if len(batch) != iterator.batch_size:\n",
        "#             print(f\"Skipping small batch of length {len(batch)}...\")\n",
        "#             continue\n",
        "          \n",
        "        model.optimizer.zero_grad()\n",
        "\n",
        "        seq, seq_lengths = batch.comment_text\n",
        "        y = batch.label.long()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            seq = seq.cuda() \n",
        "            y = y.cuda()\n",
        "            seq_lengths = seq_lengths.cuda()\n",
        "\n",
        "        preds = model.forward(seq, seq_lengths)\n",
        "\n",
        "        loss = model.loss_fcn(input=preds.squeeze(1), \n",
        "                                     target=y)\n",
        "\n",
        "        y_true = [single_tensor.item() for single_tensor in y]\n",
        "\n",
        "        indices = torch.argmax(preds, 1)\n",
        "        y_pred = [single_tensor.item() for single_tensor in indices.long()]\n",
        "\n",
        "        recall_toxic = recall_score(y_true, y_pred, pos_label=1)\n",
        "        recall_nontoxic = recall_score(y_true, y_pred, pos_label=0)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        epoch_recall += recall_toxic.item()\n",
        "        epoch_nontarget_recall += recall_nontoxic.item()\n",
        "\n",
        "        model.optimizer.step()\n",
        "        \n",
        "    last_mean_error = np.mean(np.abs(loss.item()))\n",
        "    return running_loss / len(iterator), epoch_recall / len(iterator),  epoch_nontarget_recall / len(iterator), last_mean_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHo1z3ARffLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_clf(model, iterator):\n",
        "    \n",
        "    running_loss = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_nontarget_recall = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            seq, seq_lengths = batch.comment_text\n",
        "            \n",
        "            y = batch.label.long()\n",
        "            \n",
        "            predictions = model.forward(seq, seq_lengths)\n",
        "            \n",
        "            loss = model.loss_fcn(predictions.squeeze(1), y)\n",
        "            \n",
        "            val_true = [single_tensor.item() for single_tensor in y]\n",
        "\n",
        "            indices = torch.argmax(predictions, 1)\n",
        "            val_pred = [single_tensor.item() for single_tensor in indices]\n",
        "\n",
        "            f1_toxic = f1_score(val_true, val_pred, pos_label=1)\n",
        "            f1_nontoxic = f1_score(val_true, val_pred, pos_label=0)\n",
        "        \n",
        "            recall_toxic = recall_score(val_true, val_pred, pos_label=1)\n",
        "            recall_nontoxic = recall_score(val_true, val_pred, pos_label=0)\n",
        "            \n",
        "            precision_toxic = precision_score(val_true, val_pred, pos_label=1)\n",
        "            precision_nontoxic = precision_score(val_true, val_pred, pos_label=0)\n",
        "            \n",
        "            accuracy = accuracy_score(val_true, val_pred)\n",
        "            \n",
        "            try:\n",
        "                auc_roc = roc_auc_score(val_true, val_pred)\n",
        "            except:\n",
        "                auc_roc = -1\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            epoch_recall += recall_toxic.item()\n",
        "            epoch_nontarget_recall += recall_nontoxic.item()\n",
        "  \n",
        "            metrics = {\n",
        "                \"target\": {\"f1\": round(f1_toxic * 100, 5),\n",
        "                           \"precision\": round(precision_toxic * 100, 5),\n",
        "                           \"recall\": round(recall_toxic * 100, 5)\n",
        "                          },\n",
        "                \"nontarget\": {\"f1\": round(f1_nontoxic * 100, 5),\n",
        "                           \"precision\": round(precision_nontoxic * 100, 5),\n",
        "                           \"recall\": round(recall_nontoxic * 100)\n",
        "                          },\n",
        "                \"overall\": {\"accuracy\": round(accuracy * 100, 5),\n",
        "                           \"auc_roc\": round(auc_roc * 100, 5)}\n",
        "            }\n",
        "   \n",
        "        \n",
        "    return running_loss / len(iterator), epoch_recall / len(iterator),  epoch_nontarget_recall / len(iterator), metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZu4Ql8yffLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLaTlirWCuVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loop_epochs(model, train_iter, val_iter, num_epochs, outfile=None, \n",
        "                model_prefix=None):  \n",
        "    loop_start = time.time()\n",
        "    if outfile:\n",
        "        f = open(outfile, \"a\")\n",
        "    else:\n",
        "        f = None\n",
        "      \n",
        "    # best_valid_loss = float('inf')\n",
        "    last_mean_error = -math.inf\n",
        "    best_target_recall = -1\n",
        "    best_nontarget_recall = -1\n",
        "\n",
        "    thresholds= {\n",
        "            5000: 1000,\n",
        "            1000: 100,\n",
        "            100: 10,\n",
        "            20: 5,\n",
        "            10: 3\n",
        "        }\n",
        "    metric_results = dict()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"Epoch {epoch}:\\nStarting training...\", file=f)\n",
        "        train_loss, target_recall, nontarget_recall, epoch_mean_error = train_clf(model, train_iter)\n",
        "\n",
        "        end_train = time.time()\n",
        "        train_mins, train_secs = epoch_time(start_time, end_train)\n",
        "\n",
        "        print(f\"Starting evaluation...({train_mins:02}:{train_secs:02} elapsed)\", file=f)\n",
        "        valid_loss, val_target_recall, val_nontarget_recall, metrics = evaluate_clf(model, val_iter)\n",
        "\n",
        "        end_eval = time.time()\n",
        "        eval_mins, eval_secs = epoch_time(end_train, end_eval)\n",
        "        print(f\"Finished evaluation...({eval_mins:02}:{eval_secs:02} elapsed)\", file=f)\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_eval)\n",
        "\n",
        "        metric_results[epoch] = metrics\n",
        "\n",
        "        if val_target_recall > best_target_recall:\n",
        "            best_target_recall = val_target_recall\n",
        "            savestate_file = f'{model_prefix}_epoch{epoch}_target.pt'\n",
        "            torch.save(model.state_dict(), savestate_file)\n",
        "            \n",
        "        if val_nontarget_recall > best_nontarget_recall:\n",
        "            best_nontarget_recall = val_nontarget_recall\n",
        "            savestate_file = f'{model_prefix}_epoch{epoch}_nontarget.pt'\n",
        "            torch.save(model.state_dict(), savestate_file)     \n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Total Epoch Time: {epoch_mins}m {epoch_secs}s', file=f)\n",
        "        print(f'\\tNegative Log Linear Loss:  Loss: {train_loss:.6f} | Target Recall: {target_recall*100:.2f}% | Nontarget Recall: {nontarget_recall*100:.2f}%', file=f)\n",
        "        print(f'\\tVal. Loss: {valid_loss:.6f} | Target Recall: {val_target_recall*100:.2f}% | Nontarget Recall: {val_nontarget_recall*100:.2f}%', file=f)\n",
        "        \n",
        "        \n",
        "    loop_mins, loop_secs = epoch_time(loop_start, end_eval)\n",
        "    print(f\"Total Time: {loop_mins:02}:{loop_secs:02} elapsed\", file=f)\n",
        "    print('', file=f)\n",
        "    print(metric_results, file=f)\n",
        "    print('', file=f)\n",
        "    print('', file=f)\n",
        "    f.close()\n",
        "    if outfile:\n",
        "        send_to_bucket(filename=outfile, directory=\"model_results\")\n",
        "    \n",
        "    send_to_bucket(filename=savestate_file, directory=\"model_states\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcnufZwcNRJ3",
        "colab_type": "text"
      },
      "source": [
        "### Test Model Functions on 20% of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGzu7VtffLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 6\n",
        "hist_lstm = np.zeros(NUM_EPOCHS)\n",
        "model_name=\"20_pct_dataset\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrnl5iguffLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_model = LSTMModel(vocab_size = VOCAB_SIZE, hidden_dim=100, num_layers=1, \n",
        "#                        embed_dim=300, \n",
        "                       embed_dim=200, \n",
        "                       batch_size=train_iter.batch_size,\n",
        "                       dropout=0, num_classes=2, \n",
        "                       pad_idx=TEXT.vocab.stoi[TEXT.pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-cNIvwffLL",
        "colab_type": "code",
        "outputId": "8defcf4c-ce7b-4c91-f2e1-830c3760f34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 502
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm6oe4bPffLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    lstm_model = lstm_model.cuda()\n",
        "    lstm_model.loss_fcn = lstm_model.loss_fcn.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOGOvGmP8qEy",
        "colab_type": "code",
        "outputId": "4a45f5bb-6488-4757-a0b7-050e47ec4397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy_Wg_u28rK1",
        "colab_type": "code",
        "outputId": "8be4f230-24a6-4584-fe93-498050c89ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "lstm_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9358,  0.2389, -0.9769,  ..., -0.2504,  0.6943,  0.7544],\n",
              "        [-1.0624,  1.3300, -0.2345,  ..., -0.3028,  0.8864, -0.8677],\n",
              "        [ 0.2680,  0.3603, -0.3320,  ...,  0.1777,  0.2236,  0.0142],\n",
              "        ...,\n",
              "        [-0.7283,  0.4809, -0.4850,  ...,  0.0470, -0.0370, -0.3155],\n",
              "        [-0.0343,  0.4507,  0.7884,  ..., -0.1092,  0.3405, -0.0644],\n",
              "        [-0.0034,  0.2970, -0.2874,  ...,  0.5814,  0.1632,  0.2532]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL0gKpd09D96",
        "colab_type": "code",
        "outputId": "1646ea07-bdfa-4d5e-f26d-6dc3203f56af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# let model learn from unknown token, while leaving padding as zeros\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "lstm_model.embedding.weight.data[UNK_IDX] = torch.zeros(lstm_model.embed_dim)\n",
        "lstm_model.embedding.weight.data[lstm_model.pad_idx] = torch.zeros(lstm_model.embed_dim)\n",
        "\n",
        "print(lstm_model.embedding.weight.data)"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.2680,  0.3603, -0.3320,  ...,  0.1777,  0.2236,  0.0142],\n",
            "        ...,\n",
            "        [-0.7283,  0.4809, -0.4850,  ...,  0.0470, -0.0370, -0.3155],\n",
            "        [-0.0343,  0.4507,  0.7884,  ..., -0.1092,  0.3405, -0.0644],\n",
            "        [-0.0034,  0.2970, -0.2874,  ...,  0.5814,  0.1632,  0.2532]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv2NPuqyEFhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loop_epochs(lstm_model, train_iter, val_iter, num_epochs=NUM_EPOCHS, \n",
        "            outfile='20pct_imbalanced.txt', model_prefix='20pct_imbalanced')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS13y5MAOL9v",
        "colab_type": "text"
      },
      "source": [
        "## Modeling on Rebalanced Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjPbkKUsy-wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyZbb9NmhRvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initiate_model(train_df, val_df, batch_size=BATCH_SIZE):\n",
        "    \n",
        "    TEXT = Field(tokenize=tokenizer, lower=True, include_lengths = True)\n",
        "    LABEL = Field(sequential=False, unk_token=None, \n",
        "              dtype=torch.float)\n",
        "    \n",
        "    train_ds = DataFrameDataset(train_df, fields = {'label' : LABEL, \n",
        "                                                        'comment_text': TEXT})\n",
        "    valid_ds = DataFrameDataset(val_df, fields = {'label' : LABEL, \n",
        "                                                       'comment_text': TEXT})\n",
        "#     test_ds = DataFrameDataset(test_df, fields = { 'label' : LABEL, \n",
        "#                                                        'comment_text' : TEXT})\n",
        "    print(\"Torchtext Datasets created...\")\n",
        "    TEXT.build_vocab(train_ds, max_size=25000, \n",
        "#                  vectors = \"glove.840B.300d\",\n",
        "                 vectors = \"glove.6B.200d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "    LABEL.build_vocab(train_ds)\n",
        "    \n",
        "    print(\"Torchtext vocabulary cerated...\")\n",
        "    \n",
        "    VOCAB_SIZE = len(TEXT.vocab)\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    train_iter, val_iter = BucketIterator.splits(\n",
        "    (train_ds, valid_ds), \n",
        "    batch_size = batch_size,\n",
        "    sort_key=lambda x: len(x.comment_text),\n",
        "    sort_within_batch = True,\n",
        "    device = device)\n",
        "    \n",
        "    print(\"Torchtext iterators cerated...\")\n",
        "    \n",
        "    lstm_model = LSTMModel(vocab_size = VOCAB_SIZE, hidden_dim=100, num_layers=1, \n",
        "                           embed_dim=200, \n",
        "                           batch_size=train_iter.batch_size,\n",
        "                           dropout=0, num_classes=2, \n",
        "                           pad_idx=TEXT.vocab.stoi[TEXT.pad_token])\n",
        "    \n",
        "    print(\"Model created...\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        lstm_model = lstm_model.cuda()\n",
        "        lstm_model.loss_fcn = lstm_model.loss_fcn.cuda()\n",
        "        \n",
        "    pretrained_embeddings = TEXT.vocab.vectors\n",
        "    lstm_model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "    lstm_model.embedding.weight.data[UNK_IDX] = torch.zeros(lstm_model.embed_dim)\n",
        "    lstm_model.embedding.weight.data[lstm_model.pad_idx] = torch.zeros(lstm_model.embed_dim)\n",
        "    print(\"Pre-trained embeddings applied...\")\n",
        "    \n",
        "    return lstm_model, train_iter, val_iter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CorHzdnN00YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rebalance_dict = {0: 35, 1: 50, 2: 60, 3: 65, 4:75, 5: 'random'}\n",
        "data_proportions = [0.2, 0.4, 0.6, 0.8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o8nY8D9OW4n",
        "colab_type": "text"
      },
      "source": [
        "### Rebalanced Toxicity on 20% of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnm3k6FmWUCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3c228e2d-fde6-486e-8331-39a51704c4a4"
      },
      "source": [
        "\n",
        "prepared_35, prepared_50, prepared_60, prepared_65, prepared_75, random_df = exl.rebalance_data(train_set)"
      ],
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rebalance Ratio: 0.35, 101006 toxic samples out of 288591\n",
            "Rebalance Ratio: 0.5, 144295 toxic samples out of 288591\n",
            "Rebalance Ratio: 0.6, 173154 toxic samples out of 288591\n",
            "Rebalance Ratio: 0.65, 187584 toxic samples out of 288591\n",
            "Rebalance Ratio: 0.75, 216443 toxic samples out of 288591\n",
            "Rebalanced dfs created...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs_d52XG14nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1567
        },
        "outputId": "f040577c-33e6-4a8e-84a4-f101bade0639"
      },
      "source": [
        "test_ratio=0.2\n",
        "\n",
        "for i, df in enumerate([prepared_35, prepared_50, prepared_60, prepared_65, prepared_75, random_df]):\n",
        "    model_name=f'20pct_model_{rebalance_dict[i]}toxic'\n",
        "    print(f'Model: {model_name}')\n",
        "    val_sample_df = val_set.sample( n=math.ceil(len(df)*test_ratio), random_state=1008 )\n",
        "    \n",
        "    print(f\"Validation sample_created...\")\n",
        "    \n",
        "    lstm_model, train_iter, val_iter = initiate_model(df, val_sample_df, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Beginning training and evaluation loops...\")\n",
        "\n",
        "    loop_epochs(lstm_model, train_iter, val_iter, num_epochs=NUM_EPOCHS, \n",
        "            outfile=f'{model_name}.txt', model_prefix=model_name)\n"
      ],
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: 20pct_model_35toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/20pct_model_35toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_35toxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 20pct_model_50toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/20pct_model_50toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_50toxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 20pct_model_60toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/20pct_model_60toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_60toxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 20pct_model_65toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/20pct_model_65toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_65toxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 20pct_model_75toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/20pct_model_75toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_75toxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 20pct_model_randomtoxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/20pct_model_randomtoxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][    0.0 B/    0.0 B]                                                \n",
            "Operation completed over 1 objects.                                              \n",
            "Copying file:///content/20pct_model_randomtoxic_model_state.pt [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJV8iFbOhaY",
        "colab_type": "text"
      },
      "source": [
        "### Rebalanced Toxicity on 40%, 60%, 80% of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IggXHXrwZ4RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 6\n",
        "hist_lstm = np.zeros(NUM_EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT9a8CkQlyvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjmFzYvusQ97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "e7a3774d-717c-42ff-c241-f4fb0c0470f9"
      },
      "source": [
        "for proportion in data_proportions[3:]:\n",
        "    train_set, val_set, test_set = exl.get_samples(train_full, proportion=proportion, \n",
        "                                                  train_test_ratio=(1-test_ratio))\n",
        "    pickle_to_gcs(test_set, f'{proportion*100:.0f}pct_test_set.pkl', directory=\"test_sets\")\n",
        "        \n",
        "    rebalanced_dfs = exl.rebalance_data(train_set)\n",
        "    for i, df in enumerate(rebalanced_dfs):\n",
        "#         if (rebalance_dict[i] in {35, 50, 60, 65}) and (proportion == 0.6):\n",
        "#             continue\n",
        "            \n",
        "        model_name=f'{proportion*100:.0f}pct_model_{rebalance_dict[i]}toxic'\n",
        "        \n",
        "        print(f'Model: {model_name}')\n",
        "        \n",
        "        pickle_to_gcs(df, f'{model_name}_train.pkl', directory=\"train_sets\")\n",
        "        \n",
        "        val_sample_df = val_set.sample( n=math.ceil(len(df)*test_ratio), random_state=1008 )\n",
        "        \n",
        "        pickle_to_gcs(val_sample_df, f'{model_name}_val.pkl', directory=\"val_sets\")\n",
        "\n",
        "        print(f\"Validation sample_created...\")\n",
        "\n",
        "        lstm_model, train_iter, val_iter = initiate_model(df, val_sample_df, batch_size=BATCH_SIZE)\n",
        "\n",
        "        print(f\"Beginning training and evaluation loops...\")\n",
        "\n",
        "        loop_epochs(lstm_model, train_iter, val_iter, num_epochs=NUM_EPOCHS, \n",
        "                outfile=f'{model_name}.txt', model_prefix=model_name)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieving training samples at proportion 0.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gcsfs/core.py:304: ResourceWarning: unclosed <ssl.SSLSocket fd=83, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 41142), raddr=('173.194.202.95', 443)>\n",
            "  self._singleton[0] = self\n",
            "/usr/local/lib/python3.6/dist-packages/gcsfs/core.py:304: ResourceWarning: unclosed <ssl.SSLSocket fd=82, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 46200), raddr=('74.125.20.84', 443)>\n",
            "  self._singleton[0] = self\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rebalance Ratio: 0.35, 303199 toxic samples out of 866283\n",
            "Rebalance Ratio: 0.5, 433141 toxic samples out of 866283\n",
            "Rebalance Ratio: 0.6, 519769 toxic samples out of 866283\n",
            "Rebalance Ratio: 0.65, 563083 toxic samples out of 866283\n",
            "Rebalance Ratio: 0.75, 649712 toxic samples out of 866283\n",
            "Rebalanced dfs created...\n",
            "Model: 60pct_model_75toxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/60pct_model_75toxic.txt [Content-Type=text/plain]...\n",
            "/ [1 files][  2.9 KiB/  2.9 KiB]                                                \n",
            "Operation completed over 1 objects/2.9 KiB.                                      \n",
            "Copying file:///content/60pct_model_75toxic_epoch5_target.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Model: 60pct_model_randomtoxic\n",
            "Validation sample_created...\n",
            "Torchtext Datasets created...\n",
            "Torchtext vocabulary cerated...\n",
            "Torchtext iterators cerated...\n",
            "Model created...\n",
            "Pre-trained embeddings applied...\n",
            "Beginning training and evaluation loops...\n",
            "Copying file:///content/60pct_model_randomtoxic.txt [Content-Type=text/plain]...\n",
            "\n",
            "Operation completed over 1 objects/3.0 KiB.                                      \n",
            "Copying file:///content/60pct_model_randomtoxic_epoch2_target.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/20.0 MiB.                                     \n",
            "Retrieving training samples at proportion 0.8\n",
            "Rebalance Ratio: 0.35, 404152 toxic samples out of 1154720\n",
            "Rebalance Ratio: 0.5, 577360 toxic samples out of 1154720\n",
            "Rebalance Ratio: 0.6, 692832 toxic samples out of 1154720\n",
            "Rebalance Ratio: 0.65, 750568 toxic samples out of 1154720\n",
            "Rebalance Ratio: 0.75, 866040 toxic samples out of 1154720\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}