{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pickle_functions as pf #has io, boto3, boto3.session, _pickle, pandas\n",
    "import feature_generation_functions as fgf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"s3://advancedml-koch-mathur-hinkson/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97320, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"s3://advancedml-koch-mathur-hinkson/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (100000, 45),\n",
       " (4874, 45)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100000  #chunk row size\n",
    "train_sub_dfs = [train[i:i+n] for i in range(0,train.shape[0],n)]\n",
    "\n",
    "[i.shape for i in train_sub_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:0.01 minutes\n",
      "Cleaned with stopwords...Elapsed Time:0.059 minutes\n",
      "Cleaned without stopwords...Elapsed Time:0.082 minutes\n",
      "Stemmed (Porter)...Elapsed Time:2.248 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:1.815 minutes\n",
      "Created bigrams...Elapsed Time:4.25 minutes\n",
      "Calculated uppercase pct...Elapsed Time:0.009 minutes\n",
      "Count punctuation...Elapsed Time:0.003 minutes\n",
      "Count words...Elapsed Time:0.001 minutes\n",
      "Count stopwords pct...Elapsed Time:0.035 minutes\n",
      "Count uppercase words...Elapsed Time:0.008 minutes\n"
     ]
    }
   ],
   "source": [
    "test_preprocessed = add_text_cleaning_cols(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocessed.to_pickle('test_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.065 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.083 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.618 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.326 minutes\n",
      "Created bigrams...Elapsed Time:  0.035 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.019 minutes\n",
      "Count punctuation...Elapsed Time:  0.013 minutes\n",
      "Count words...Elapsed Time:  0.012 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.018 minutes\n"
     ]
    }
   ],
   "source": [
    "sub_train_df1 = train_sub_dfs[0]\n",
    "sub_train_df1_preprocessed = generate_features(sub_train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df1_preprocessed.to_pickle('sub_train_df1_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.067 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.084 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.652 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.354 minutes\n",
      "Created bigrams...Elapsed Time:  0.034 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.018 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "sub_train_df2 = train_sub_dfs[1]\n",
    "sub_train_df2_preprocessed = generate_features(sub_train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df2_preprocessed.to_pickle('sub_train_df2_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.013 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.066 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.085 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.645 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.36 minutes\n",
      "Created bigrams...Elapsed Time:  0.034 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.018 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "sub_train_df3 = train_sub_dfs[2]\n",
    "sub_train_df3_preprocessed = generate_features(sub_train_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df3_preprocessed.to_pickle('sub_train_df3_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.064 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.081 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.572 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.329 minutes\n",
      "Created bigrams...Elapsed Time:  0.033 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.017 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "sub_train_df4 = train_sub_dfs[3]\n",
    "sub_train_df4_preprocessed = generate_features(sub_train_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df4_preprocessed.to_pickle('sub_train_df4_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.063 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.08 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.533 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.299 minutes\n",
      "Created bigrams...Elapsed Time:  0.033 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.039 minutes\n",
      "Count uppercase words...Elapsed Time:  0.017 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "sub_train_df5 = train_sub_dfs[4]\n",
    "sub_train_df5_preprocessed = generate_features(sub_train_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df5_preprocessed.to_pickle('sub_train_df5_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.013 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.062 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.078 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.514 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.277 minutes\n",
      "Created bigrams...Elapsed Time:  0.033 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.017 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "sub_train_df6 = train_sub_dfs[5]\n",
    "sub_train_df6_preprocessed = generate_features(sub_train_df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_s3bucket('sub_train_df6_preprocessed.pkl', sub_train_df6_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.064 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.081 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.567 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.319 minutes\n",
      "Created bigrams...Elapsed Time:  0.034 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.019 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.012 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.018 minutes\n",
      "DONE GENERATING FEATURES\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle_to_s3bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4b7b1418cf39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub_train_df7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sub_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msub_train_df7_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_train_df7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle_to_s3bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sub_train_df7_preprocessed.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_train_df7_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sent to bucket\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle_to_s3bucket' is not defined"
     ]
    }
   ],
   "source": [
    "sub_train_df7 = train_sub_dfs[6]\n",
    "sub_train_df7_preprocessed = generate_features(sub_train_df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_s3bucket('sub_train_df7_preprocessed.pkl', sub_train_df7_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.014 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.065 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.083 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.574 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.348 minutes\n",
      "Created bigrams...Elapsed Time:  0.034 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.018 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.017 minutes\n",
      "DONE GENERATING FEATURES\n",
      "sent to bucket\n"
     ]
    }
   ],
   "source": [
    "sub_train_df8 = train_sub_dfs[7]\n",
    "sub_train_df8_preprocessed = generate_features(sub_train_df8)\n",
    "pickle_to_s3bucket('sub_train_df8_preprocessed.pkl', sub_train_df8_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_s3bucket('sub_train_df8_preprocessed.pkl', sub_train_df8_preprocessed, 'advancedml-koch-mathur-hinkson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.015 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.067 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.086 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.611 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.361 minutes\n",
      "Created bigrams...Elapsed Time:  0.035 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.019 minutes\n",
      "Count punctuation...Elapsed Time:  0.013 minutes\n",
      "Count words...Elapsed Time:  0.012 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.018 minutes\n",
      "\n",
      "DONE GENERATING FEATURES\n",
      "Pickled and sent to bucket!\n"
     ]
    }
   ],
   "source": [
    "sub_train_df9 = train_sub_dfs[8]\n",
    "sub_train_df9_preprocessed = fgf.generate_features(sub_train_df9)\n",
    "pf.pickle_to_s3bucket('sub_train_df9_preprocessed.pkl', sub_train_df9_preprocessed, 'advancedml-koch-mathur-hinkson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.012 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.064 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.081 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.56 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.317 minutes\n",
      "Created bigrams...Elapsed Time:  0.033 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.019 minutes\n",
      "Count punctuation...Elapsed Time:  0.012 minutes\n",
      "Count words...Elapsed Time:  0.011 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.038 minutes\n",
      "Count uppercase words...Elapsed Time:  0.017 minutes\n",
      "\n",
      "DONE GENERATING FEATURES\n",
      "Pickled and sent to bucket!\n"
     ]
    }
   ],
   "source": [
    "sub_train_df10 = train_sub_dfs[9]\n",
    "sub_train_df10_preprocessed = fgf.generate_features(sub_train_df10)\n",
    "pf.pickle_to_s3bucket('sub_train_df10_preprocessed.pkl', sub_train_df10_preprocessed, 'advancedml-koch-mathur-hinkson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split comments...Elapsed Time:  0.022 minutes\n",
      "Cleaned with stopwords...Elapsed Time:  0.062 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.083 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  1.55 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  1.284 minutes\n",
      "Created bigrams...Elapsed Time:  0.035 minutes\n",
      "Calculated uppercase pct...Elapsed Time:  0.02 minutes\n",
      "Count punctuation...Elapsed Time:  0.014 minutes\n",
      "Count words...Elapsed Time:  0.013 minutes\n",
      "Count stopwords pct...Elapsed Time:  0.04 minutes\n",
      "Count uppercase words...Elapsed Time:  0.019 minutes\n",
      "\n",
      "DONE GENERATING FEATURES\n",
      "Pickled and sent to bucket!\n"
     ]
    }
   ],
   "source": [
    "sub_train_df11 = train_sub_dfs[10]\n",
    "sub_train_df11_preprocessed = fgf.generate_features(sub_train_df11)\n",
    "pf.write_pickle_to_s3bucket('sub_train_df11_preprocessed.pkl', sub_train_df11_preprocessed, 'advancedml-koch-mathur-hinkson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df12 = train_sub_dfs[11]\n",
    "sub_train_df12_preprocessed = fgf.generate_features(sub_train_df12)\n",
    "pf.write_pickle_to_s3bucket('sub_train_df12_preprocessed.pkl', sub_train_df12_preprocessed, 'advancedml-koch-mathur-hinkson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
